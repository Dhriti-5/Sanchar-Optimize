# Sanchar-Optimize Backend - Phase 2

**Scalable FastAPI Backend for Agentic Content Resiliency System**

## ğŸ—ï¸ Architecture Overview

This backend implements three core agentic components:

1. **Network Sentry Agent** - Predictive network monitoring with LSTM models
2. **Modality Orchestrator** - AI-powered decision engine using Amazon Bedrock
3. **Multi-Modal Transformer** - RAG-based content summarization pipeline

## ğŸ“ Project Structure

```
Backend/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment configuration template
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/                     # API endpoints
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ telemetry.py         # Telemetry ingestion endpoints
â”‚   â”‚   â”œâ”€â”€ modality.py          # Modality decision endpoints
â”‚   â”‚   â””â”€â”€ health.py            # Health check endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                    # Core configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py            # Application settings
â”‚   â”‚   â”œâ”€â”€ logging_config.py    # Logging configuration
â”‚   â”‚   â””â”€â”€ security.py          # Security utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # Data models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ telemetry.py         # Telemetry data models
â”‚   â”‚   â”œâ”€â”€ modality.py          # Modality decision models
â”‚   â”‚   â””â”€â”€ content.py           # Content models
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ network_sentry.py    # Network prediction service
â”‚   â”‚   â”œâ”€â”€ modality_orchestrator.py  # Decision engine service
â”‚   â”‚   â””â”€â”€ multi_modal_transformer.py  # Content transformation service
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                      # Machine learning models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lstm_predictor.py    # LSTM time-series prediction
â”‚   â”‚   â””â”€â”€ model_loader.py      # Model loading utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ aws/                     # AWS integrations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bedrock_client.py    # Amazon Bedrock client
â”‚   â”‚   â”œâ”€â”€ timestream_client.py # AWS Timestream client
â”‚   â”‚   â”œâ”€â”€ s3_client.py         # S3 storage client
â”‚   â”‚   â””â”€â”€ lambda_edge.py       # Lambda@Edge deployment
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                      # Database clients
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ redis_client.py      # Redis cache
â”‚   â”‚   â””â”€â”€ dynamodb_client.py   # DynamoDB session store
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ telemetry_processor.py
â”‚       â””â”€â”€ validators.py
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â””â”€â”€ property/                # Property-based tests (Hypothesis)
â”‚
â”œâ”€â”€ deployment/                  # Deployment configurations
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ lambda/
â”‚   â”‚   â””â”€â”€ template.yaml        # SAM template
â”‚   â””â”€â”€ terraform/               # Infrastructure as Code
â”‚
â””â”€â”€ scripts/                     # Utility scripts
    â”œâ”€â”€ train_lstm_model.py
    â””â”€â”€ setup_aws_resources.py
```

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.9+
- AWS Account with Bedrock access
- Redis (optional, for caching)

### 2. Installation

```powershell
# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Copy environment configuration
cp .env.example .env
# Edit .env with your AWS credentials
```

### 3. Configuration

Edit `.env` file with your credentials:
- AWS credentials
- Amazon Bedrock model ID
- Database connection strings

### 4. Run Development Server

```powershell
# Run with hot reload
python main.py

# Or with uvicorn directly
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 5. Test the API

```powershell
# Health check
curl http://localhost:8000/api/v1/health

# View API documentation
# Open: http://localhost:8000/docs
```

## ğŸ“¡ API Endpoints

### Health & Status
- `GET /` - Root endpoint
- `GET /api/v1/health` - Health check
- `GET /api/v1/health/ready` - Readiness probe
- `GET /api/v1/health/live` - Liveness probe

### Telemetry
- `POST /api/v1/telemetry` - Submit network telemetry
- `POST /api/v1/telemetry/batch` - Batch telemetry submission
- `GET /api/v1/telemetry/predict` - Get signal drop prediction

### Modality Decision
- `POST /api/v1/modality/decide` - Get modality transition decision
- `POST /api/v1/modality/panic` - Handle panic signal from extension
- `GET /api/v1/modality/status/{session_id}` - Get current modality status

### Content Transformation
- `POST /api/v1/transform/summary` - Generate AI summary
- `GET /api/v1/transform/transcript/{content_id}` - Get cached transcript

## ğŸ§ª Testing

```powershell
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run property-based tests
pytest tests/property/

# Run specific test file
pytest tests/unit/test_network_sentry.py
```

## ğŸ”§ Development

### Code Quality

```powershell
# Format code
black .

# Lint
flake8

# Type checking
mypy app/
```

### Training ML Models

```powershell
# Train LSTM predictor
python scripts/train_lstm_model.py --data ./data/telemetry.csv
```

## ğŸš¢ Deployment

### Docker

```powershell
# Build image
docker build -t sanchar-optimize-backend -f deployment/docker/Dockerfile .

# Run container
docker run -p 8000:8000 --env-file .env sanchar-optimize-backend
```

### AWS Lambda@Edge

```powershell
# Deploy with SAM
cd deployment/lambda
sam build
sam deploy --guided
```

### Terraform

```powershell
# Initialize
cd deployment/terraform
terraform init

# Plan
terraform plan

# Apply
terraform apply
```

## ğŸ“Š Monitoring

- **Metrics**: Prometheus metrics exposed at `/metrics`
- **Logs**: Structured JSON logging to stdout
- **Tracing**: AWS X-Ray integration (optional)

## ğŸ” Security

- CORS configured for extension origins
- Rate limiting per IP/session
- Input validation with Pydantic
- AWS credentials via IAM roles (production)

## ğŸ¤ Contributing

1. Check the implementation against [design.md](../design.md)
2. Follow property-based testing guidelines
3. Maintain >80% code coverage
4. All tests must pass

## ğŸ“š Additional Resources

- [Design Document](../design.md)
- [Requirements](../requirements.md)
- [Phase 1 Quick Start](../QUICK_START_PHASE1.md)
- [Extension README](../extension/README.md)

## ğŸ“ License

Built for **AI for Bharat Hackathon 2026** by Team Eka

---

**Status**: Phase 2 - Backend Implementation Complete âœ…
